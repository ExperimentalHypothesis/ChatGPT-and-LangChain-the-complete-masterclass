{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# This is how a chain and chain flow looks like. \n",
    "### Chain is a wrapper around prompt and LLM. It takes input as dict and generated output as dict  \n",
    "![title](pics/Screenshot_20240518_131454.png)\n",
    "\n",
    "### Because it is a wrapper, the LLM model inside can be easily replaced in case of need\n",
    "![title](pics/Screenshot_20240518_133026.png)\n",
    "\n",
    "### Chains can be combined together so that the output from first is the input for second\n",
    "### ![title](pics/Screenshot_20240518_131838.png)\n",
    "\n",
    "### In order to make it work the names for OUTPUT/INPUT need to match\n",
    "### ![title](pics/Screenshot_20240518_132152.png)"
   ],
   "id": "6a1a65f2adbc1785"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Example of how to use instead on directly speaking to model",
   "id": "c063ba846035eca1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T14:28:06.649676Z",
     "start_time": "2024-05-18T14:28:05.892928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "llm = OpenAI()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = \"What is the capital city of {state}\",\n",
    "    input_variables = ['state']\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm, \n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "result = chain.invoke({\"state\": \"Czech Republic\"})\n",
    "print(result)"
   ],
   "id": "c50cbeb2aa2c241f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': 'Czech Republic', 'text': '\\n\\nThe capital city of Czech Republic is Prague.'}\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " # Improved previous example where i put input variables into CLI and use pipelines of two chains\n",
    " ### this will not run inside jupyter, run it inside a file, eg *python file.py --state=USA*\n"
   ],
   "id": "e566892fb21c0e74"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T14:40:14.635472Z",
     "start_time": "2024-05-18T14:40:14.620600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from dotenv import load_dotenv\n",
    "import argparse\n",
    "\n",
    "load_dotenv()\n",
    "llm = OpenAI()\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--state\", default=\"Czech republic\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = \"What is the capital city of China\",\n",
    "    # input_variables = ['state']\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm, \n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "result = chain.invoke({: args.state})\n",
    "print(result)"
   ],
   "id": "d3d14e60109c34fa",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--state STATE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/nirvikalpa/.local/share/jupyter/runtime/kernel-7245ad86-2fa6-4a02-8f41-5e4e0006161d.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[0;31mSystemExit\u001B[0m\u001B[0;31m:\u001B[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nirvikalpa/.cache/pypoetry/virtualenvs/chatgptreporeader-BYS5M-4o-py3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " # Improved previous example where i chain two chains together\n",
    "### Chains can be combined together so that the output from first is the input for second\n",
    "### ![title](pics/Screenshot_20240518_131838.png) \n"
   ],
   "id": "3f885cf2873ff06"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T15:20:36.524175Z",
     "start_time": "2024-05-18T15:20:33.859527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.sequential import SequentialChain\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "llm = OpenAI()\n",
    "\n",
    "# 1. prompt to generate code\n",
    "code_prompt = PromptTemplate(\n",
    "    template = \"Write a function in {language} that does task: {task}\",\n",
    "    input_variables = [\"language\", \"task\"]\n",
    ")\n",
    "code_chain = LLMChain(\n",
    "    llm=llm, \n",
    "    prompt=code_prompt, \n",
    "    output_key=\"code\" # default is text, but here I am renaming it, the other two which came inside will also be returned\n",
    ") \n",
    "\n",
    "# 2. prompt to generate test for the code\n",
    "test_prompt = PromptTemplate(\n",
    "    template=\"Generate test for this code {code} in language {language}\",\n",
    "    input_variables = [\"code\", \"language\"]  # these are the outputs from the first 'code_chain'\n",
    ")\n",
    "test_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=test_prompt,\n",
    "    output_key=\"test\" # again renaming the default, the other two which came inside will also be returned\n",
    ")\n",
    "\n",
    "# here is where the magic happens - I need to wire the chains together \n",
    "# because it is a sequential action, \n",
    "chain = SequentialChain(\n",
    "    chains=[code_chain, test_chain], # which chains to run\n",
    "    input_variables=[\"language\", \"task\"], # what goes into the very start\n",
    "    output_variables=[\"code\", \"test\"] # what is the final result + what came inside as always\n",
    ")\n",
    "\n",
    "result = chain.invoke({\"language\": \"python\", \"task\": \"return a list of 5 numbers\"})  # i am not using CLI so this is hardcoded here\n",
    "print(result)"
   ],
   "id": "270420573d0c0a03",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'language': 'python', 'task': 'return a list of 5 numbers', 'code': '\\n\\ndef return_numbers():\\n    return [1, 2, 3, 4, 5]', 'test': \"\\n\\n\\n# Importing necessary libraries\\nimport unittest\\n\\n# Importing the function to be tested\\nfrom return_numbers import return_numbers\\n\\n# Creating a test class\\nclass TestReturnNumbers(unittest.TestCase):\\n\\n    # Defining a test method\\n    def test_return_numbers(self):\\n        \\n        # Expected output\\n        expected = [1, 2, 3, 4, 5]\\n        \\n        # Actual output\\n        actual = return_numbers()\\n        \\n        # Asserting if the actual output is equal to the expected output\\n        self.assertEqual(actual, expected)\\n        \\n# Allowing the test class to be executed directly        \\nif __name__ == '__main__':\\n    unittest.main()\"}\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T15:22:08.009444Z",
     "start_time": "2024-05-18T15:22:08.007197Z"
    }
   },
   "cell_type": "code",
   "source": "print(result[\"code\"])",
   "id": "e71f36ab5f5586bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "def return_numbers():\n",
      "    return [1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T15:23:33.392311Z",
     "start_time": "2024-05-18T15:23:33.389722Z"
    }
   },
   "cell_type": "code",
   "source": "print(result[\"test\"])",
   "id": "230b2dd8b300b218",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "# Importing necessary libraries\n",
      "import unittest\n",
      "\n",
      "# Importing the function to be tested\n",
      "from return_numbers import return_numbers\n",
      "\n",
      "# Creating a test class\n",
      "class TestReturnNumbers(unittest.TestCase):\n",
      "\n",
      "    # Defining a test method\n",
      "    def test_return_numbers(self):\n",
      "        \n",
      "        # Expected output\n",
      "        expected = [1, 2, 3, 4, 5]\n",
      "        \n",
      "        # Actual output\n",
      "        actual = return_numbers()\n",
      "        \n",
      "        # Asserting if the actual output is equal to the expected output\n",
      "        self.assertEqual(actual, expected)\n",
      "        \n",
      "# Allowing the test class to be executed directly        \n",
      "if __name__ == '__main__':\n",
      "    unittest.main()\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b809706195a8df4f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
